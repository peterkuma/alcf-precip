#!/usr/bin/env python3
'''Train or apply the artificial neural network (ANN).

Usage: ann train INPUT INPUT_VAL OUTPUT OUTPUT_HISTORY [OPTIONS]
       ann apply MODEL INPUT OUTPUT [OPTIONS]

This program uses PST for command line argument parsing.

Arguments (ann train):

  INPUT           Input directory with samples. The output of prepare_samples (NetCDF).
  INPUT_VAL       Input directory with validation samples (NetCDF).
  OUTPUT          Output model (HDF5).
  OUTPUT_HISTORY  History output (NetCDF).

Arguments (ann apply):

  MODEL   TensorFlow model (HDF5).
  INPUT   Input directory with samples. The output of prepare_samples (NetCDF).
  OUTPUT  Output samples directory (NetCDF).

Options:

  nclasses: VALUE  Number of cloud types. One of: 4, 10, 27. Default: 4.

Examples:

bin/ann train data/samples_train data/samples_val data/ann.h5 data/history.nc
bin/ann apply data/ann.h5 data/samples data/samples_pred
'''

import warnings
warnings.filterwarnings('ignore')

import sys
import re
import os
import random
import numpy as np
import ds_format as ds
import aquarius_time as aq
import matplotlib.pyplot as plt
import pst
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Model
from keras.layers.merge import concatenate
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, \
	AveragePooling2D, MaxPooling2D, Flatten, Dense, Dropout, \
	BatchNormalization, Activation
from tensorflow.keras.utils import Sequence

def get_loss_func(nclasses):
	def loss_func(y_true, y_pred):
		a = y_true[:,:,:,0:nclasses]
		b = y_true[:,:,:,nclasses:(2*nclasses)]
		c = y_pred[:,:,:,0:nclasses]
		#c = tf.nn.sigmoid(y_pred[:,:,:,0:nclasses])
		#c = tf.minimum(tf.maximum(c, 0), 1)
		d = a*tf.experimental.numpy.log(c) + \
			(b - a)*tf.experimental.numpy.log(1 - c)
		#d = (b - a)*tf.experimental.numpy.log(1 - c)
		x = -tf.experimental.numpy.sum(d)
		#x = tf.experimental.numpy.sum((c - a)**2)
		return x
	return loss_func

def unet_encoder(x, n, kernel_size=3, batchnorm=True, dropout=0, maxpool=True):
	y = Conv2D(n, (kernel_size, kernel_size), kernel_initializer='he_normal', \
		padding='same', activation='relu')(x)
	#if batchnorm:
	#	y = BatchNormalization()(y)
	#y = Activation('relu')(y)
	y = Conv2D(n, (kernel_size, kernel_size), kernel_initializer='he_normal', \
		padding='same', activation='relu')(x)
	#if batchnorm:
	#	y = BatchNormalization()(y)
	#y = Activation('relu')(y)
	z = y
	if maxpool:
		y = AveragePooling2D((2, 2))(y)
	if dropout > 0:
		y = Dropout(dropout)(y)
	return y, z

def unet_decoder(x, z, n, kernel_size=3, batchnorm=True, dropout=0):
	y = Conv2DTranspose(n, (kernel_size, kernel_size), strides=(2, 2),
		padding='same')(x)
	y = concatenate([y, z])
	y = Dropout(dropout)(y)
	y, _ = unet_encoder(y, n, kernel_size, batchnorm, 0, False)
	return y

def unet_model(x, nclasses, n=16, dropout=0.1, batchnorm=True):
	y, c1 = unet_encoder(x, n*1, 3, batchnorm, dropout)
	y, c2 = unet_encoder(y, n*2, 3, batchnorm, dropout)
	#y, c3 = unet_encoder(y, n*4, 3, batchnorm, dropout)
	#y, c4 = unet_encoder(y, n*8, 3, batchnorm, dropout)
	y, c5 = unet_encoder(y, n*4, 3, batchnorm, 0, False)
	#y = unet_decoder(y, c4, n*8, 3, batchnorm, dropout)
	#y = unet_decoder(y, c3, n*4, 3, batchnorm, dropout)
	y = unet_decoder(y, c2, n*2, 3, batchnorm, dropout)
	y = unet_decoder(y, c1, n*1, 3, batchnorm, dropout)
	y = Conv2D(nclasses*2, (1, 1), activation='sigmoid')(y)
	return Model(inputs=[x], outputs=[y])

if __name__ == '__main__':
	nclasses = 4

	train_images = np.ones((920, 12, 300, 1), np.float64)
	train_labels = np.ones((920, 12, 300, 8), np.float64)
	train_labels[:,:,:,:4] = 0.1

	policy = tf.keras.mixed_precision.Policy('float64')
	tf.keras.mixed_precision.set_global_policy(policy)

	input_ = Input((12, 300, 1))
	model = unet_model(input_, nclasses, 16, 0.1, True)

	model.compile(optimizer='adam',
				  loss=get_loss_func(nclasses),
				  metrics=['accuracy'])

	history = model.fit(train_images, train_labels,
		epochs=10,
	)

	stats1 = model.predict(train_images)
	print(np.mean(stats1[:,:,:,:4]))
