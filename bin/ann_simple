#!/usr/bin/env python3
'''Train or apply the artificial neural network (ANN).

Usage: ann_simple train INPUT INPUT_VAL OUTPUT OUTPUT_HISTORY [OPTIONS]
       ann_simple apply MODEL INPUT OUTPUT [OPTIONS]

This program uses PST for command line argument parsing.

Arguments (ann train):

  INPUT           Input directory with samples. The output of prepare_samples (NetCDF).
  INPUT_VAL       Input directory with validation samples (NetCDF).
  OUTPUT          Output model (HDF5).
  OUTPUT_HISTORY  History output (NetCDF).

Arguments (ann apply):

  MODEL   TensorFlow model (HDF5).
  INPUT   Input directory with samples. The output of prepare_samples (NetCDF).
  OUTPUT  Output samples directory (NetCDF).

Examples:

bin/ann train data/samples_train data/samples_val data/ann.h5 data/history.nc
bin/ann apply data/ann.h5 data/samples data/samples_pred
'''

import warnings
warnings.filterwarnings('ignore')

import sys
import os
import numpy as np
import ds_format as ds
import pst
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

def create_model():
	m = Sequential()
	m.add(Conv2D(64, (3, 3), activation='relu', input_shape=(16, 24, 1), padding='same'))
	m.add(MaxPooling2D((2, 2)))
	m.add(Conv2D(128, (3, 3), activation='relu'))
	m.add(MaxPooling2D((2, 2)))
	m.add(Conv2D(256, (3, 3), activation='relu'))
	m.add(MaxPooling2D((1, 2)))
	m.add(Dropout(0.2))
	m.add(Flatten())
	m.add(Dense(64, activation='relu'))
	m.add(Dense(4))
	return m

def read_sample(filename):
	print('<- %s' % filename)
	d = ds.read(filename, ['time_bnds', 'backscatter'])
	time_bnds = np.array([d['time_bnds'][0,0], d['time_bnds'][-1,1]])
	time_bnds = time_bnds.reshape(1, 2)
	backscatter = d['backscatter']
	image = d['backscatter'].copy()/1e-6
	image = image[:,:24]
	image = image.reshape([1] + list(image.shape) + [1])
	image[image < 0] = 0
	image[np.isnan(image)] = -1
	if ds.attr(d, 'label'):
		label = {
			'clear': 0,
			'rain': 1,
			'snow': 2,
			'fog': 3
		}[ds.attr(d, 'label')]
	else:
		label = -1
	return time_bnds, image, label

def read_dataset(input_):
	images = []
	labels = []
	time_bndss = []
	for file_ in sorted(os.listdir(input_)):
		if not file_.endswith('.nc'):
			continue
		filename = os.path.join(input_, file_)
		time_bnds, image, label = read_sample(filename)
		time_bndss += [time_bnds]
		images += [image]
		labels += [label]
	time_bndss = np.concatenate(time_bndss)
	images = np.concatenate(images)
	labels = np.array(labels)
	return time_bndss, images, labels

def apply_(model_file, input_, output):
	model = tf.keras.models.load_model(model_file)
	time_bnds, images, labels = read_dataset(input_)
	results = tf.nn.softmax(model.predict(images)).numpy()
	print('-> %s' % output)
	ds.write(output, {
		'time_bnds': time_bnds,
		'label': labels,
		'pred': results,
		'.': {
			'time_bnds': {
				'.dims': ['time', 'bnds'],
				'long_name': 'time bounds',
				'units': ds.drivers.netcdf.JD_UNITS,
				'calendar': ds.drivers.netcdf.JD_CALENDAR,
			},
			'label': {
				'.dims': ['time'],
				'long_name': 'true label',
			},
			'pred': {
				'.dims': ['time', 'label'],
				'long_name': 'predicted label probabilities',
			},
		}
	})

def train(input_, input_val, output, output_history):
	_, train_images, train_labels = read_dataset(input_)
	_, val_images, val_labels = read_dataset(input_val)

	policy = tf.keras.mixed_precision.Policy('float64')
	tf.keras.mixed_precision.set_global_policy(policy)

	model = create_model()

	model.compile(
		optimizer='adam',
		loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
		metrics=['accuracy']
	)

	callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)

	history = model.fit(train_images, train_labels,
		epochs=100,
		validation_data=(val_images, val_labels),
		callbacks=[callback],
	)

	print('-> %s' % output)
	model.save(output)

	ds.write(output_history, {
		'loss': np.array(history.history['loss']),
		'val_loss': np.array(history.history['val_loss']),
		'.': {
			'loss': {'.dims': ['round']},
			'val_loss': {'.dims': ['round']},
		},
	})

if __name__ == '__main__':
	args, opts = pst.decode_argv(sys.argv, as_unicode=True)
	if len(args) < 2:
		sys.stderr.write(sys.modules[__name__].__doc__)
		sys.exit(1)
	action = args[1]

	tf.config.threading.set_inter_op_parallelism_threads(24)

	if action == 'train':
		if len(args) != 6:
			sys.stderr.write(sys.modules[__name__].__doc__)
			sys.exit(1)
		input_ = args[2]
		input_val = args[3]
		output = args[4]
		output_history = args[5]
		train(input_, input_val, output, output_history)
	elif action == 'apply':
		if len(args) != 5:
			sys.stderr.write(sys.modules[__name__].__doc__)
			sys.exit(1)
		model = args[2]
		input_ = args[3]
		output = args[4]
		apply_(model, input_, output)
	else:
		raise ValueError('Unknown action "%s"' % action)
